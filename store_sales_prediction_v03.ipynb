{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.406623Z",
     "start_time": "2022-08-14T00:09:41.682372Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minflection\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m                 \u001b[38;5;28;01mimport\u001b[39;00m stats  \u001b[38;5;28;01mas\u001b[39;00m ss\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboruta\u001b[39;00m                \u001b[38;5;28;01mimport\u001b[39;00m BorutaPy\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import inflection\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy                 import stats  as ss\n",
    "from boruta                import BorutaPy\n",
    "from matplotlib            import pyplot as plt\n",
    "from IPython.display       import Image\n",
    "from IPython.core.display  import HTML\n",
    "\n",
    "\n",
    "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.linear_model  import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.415619Z",
     "start_time": "2022-08-14T00:10:06.415619Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "        # start and end date for validation \n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta( days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta( days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop( ['date', 'sales'], axis=1 ) \n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "\n",
    "        # prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1( yhat ) )\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(  m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )\n",
    "\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "     \n",
    "    \n",
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y ) )\n",
    "\n",
    "    \n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    \n",
    "    return pd.DataFrame( { 'Model Name': model_name, \n",
    "                           'MAE': mae, \n",
    "                           'MAPE': mape,\n",
    "                           'RMSE': rmse }, index=[0] )\n",
    "\n",
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).as_matrix()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
    "\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.419618Z",
     "start_time": "2022-08-14T00:10:06.419618Z"
    }
   },
   "outputs": [],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.422615Z",
     "start_time": "2022-08-14T00:10:06.422615Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv( '../data/train.csv', low_memory=False )\n",
    "df_store_raw = pd.read_csv( '../data/store.csv', low_memory=False )\n",
    "\n",
    "# merge\n",
    "df_raw = pd.merge( df_sales_raw, df_store_raw, how='left', on='Store' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. PASSO 01 - DESCRICAO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.426618Z",
     "start_time": "2022-08-14T00:10:06.426618Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.1. Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.428612Z",
     "start_time": "2022-08-14T00:10:06.428612Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "            'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "# rename\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.2. Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.431611Z",
     "start_time": "2022-08-14T00:10:06.431611Z"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Number of Cols: {}'.format( df1.shape[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.3. Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.433610Z",
     "start_time": "2022-08-14T00:10:06.433610Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime( df1['date'] )\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.438606Z",
     "start_time": "2022-08-14T00:10:06.438606Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.5. Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.440605Z",
     "start_time": "2022-08-14T00:10:06.440605Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.443603Z",
     "start_time": "2022-08-14T00:10:06.443603Z"
    }
   },
   "outputs": [],
   "source": [
    "#competition_distance        \n",
    "df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "\n",
    "#competition_open_since_month\n",
    "df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "#competition_open_since_year \n",
    "df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "#promo2_since_week           \n",
    "df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "#promo2_since_year           \n",
    "df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "#promo_interval              \n",
    "month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df1['promo_interval'].fillna(0, inplace=True )\n",
    "\n",
    "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.445603Z",
     "start_time": "2022-08-14T00:10:06.445603Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.6. Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.448601Z",
     "start_time": "2022-08-14T00:10:06.448601Z"
    }
   },
   "outputs": [],
   "source": [
    "# competiton\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "    \n",
    "# promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "## 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.450599Z",
     "start_time": "2022-08-14T00:10:06.450599Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'float64'] )\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "### 1.7.1. Numerical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.455598Z",
     "start_time": "2022-08-14T00:10:06.455598Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Central Tendency - mean, meadina \n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T \n",
    "d2 = pd.DataFrame( num_attributes.apply( min ) ).T \n",
    "d3 = pd.DataFrame( num_attributes.apply( max ) ).T \n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T \n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T \n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T \n",
    "\n",
    "# concatenar\n",
    "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.458595Z",
     "start_time": "2022-08-14T00:10:06.458595Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot( df1['competition_distance'], kde=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    }
   },
   "source": [
    "### 1.7.2. Categorical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.460593Z",
     "start_time": "2022-08-14T00:10:06.460593Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_attributes.apply( lambda x: x.unique().shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.463591Z",
     "start_time": "2022-08-14T00:10:06.463591Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.boxplot( x='state_holiday', y='sales', data=aux )\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.boxplot( x='store_type', y='sales', data=aux )\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.boxplot( x='assortment', y='sales', data=aux )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. PASSO 02 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.466590Z",
     "start_time": "2022-08-14T00:10:06.466590Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Mapa Mental de Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.470587Z",
     "start_time": "2022-08-14T00:10:06.470587Z"
    }
   },
   "outputs": [],
   "source": [
    "Image( 'img/MindMapHypothesis.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Criacao das Hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Hipoteses Loja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas com número maior de funcionários deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior capacidade de estoque deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com maior porte deveriam vender mais.\n",
    "\n",
    "**4.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**6.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Hipoteses Produto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:22:20.284469Z",
     "start_time": "2019-11-16T21:22:20.236577Z"
    }
   },
   "source": [
    "**1.** Lojas que investem mais em Marketing deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior exposição de produto deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com produtos com preço menor deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com promoções mais agressivas ( descontos maiores ), deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**8.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Hipoteses Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:24:09.377189Z",
     "start_time": "2019-11-16T21:24:09.339135Z"
    }
   },
   "source": [
    "**1.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**2.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**3.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**4.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**5.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**6.** Lojas deveriam vender menos durante os feriados escolares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Lista Final de Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**3.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "**8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**12.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**13.** Lojas deveriam vender menos durante os feriados escolares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.474585Z",
     "start_time": "2022-08-14T00:10:06.474585Z"
    }
   },
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "# competition since\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "# state holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.477583Z",
     "start_time": "2022-08-14T00:10:06.477583Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Filtragem das Linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.480583Z",
     "start_time": "2022-08-14T00:10:06.480583Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Selecao das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.483582Z",
     "start_time": "2022-08-14T00:10:06.483582Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. PASSO 04 - ANALISE EXPLORATORIA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.489577Z",
     "start_time": "2022-08-14T00:10:06.489577Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Analise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### 4.1.1. Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.491575Z",
     "start_time": "2022-08-14T00:10:06.491575Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sns.distplot( df4['sales'], kde=False  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.494574Z",
     "start_time": "2022-08-14T00:10:06.494574Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "num_attributes.hist( bins=25 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### 4.1.3. Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.497573Z",
     "start_time": "2022-08-14T00:10:06.497573Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "plt.subplot( 3, 2, 1 )\n",
    "a = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot( a['state_holiday'] )\n",
    "\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True )\n",
    "\n",
    "# store_type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "sns.countplot( df4['store_type'] )\n",
    "\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', shade=True )\n",
    "\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "sns.countplot( df4['assortment'] )\n",
    "\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Analise Bivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### **H1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "**FALSA** Lojas com MAIOR SORTIMENTO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.500571Z",
     "start_time": "2022-08-14T00:10:06.500571Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index()\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby( ['year_week','assortment'] ).sum().reset_index()\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
    "\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "**FALSA** Lojas com COMPETIDORES MAIS PROXIMOS vendem MAIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.505569Z",
     "start_time": "2022-08-14T00:10:06.505569Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby( 'competition_distance' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.scatterplot( x ='competition_distance', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "bins = list( np.arange( 0, 20000, 1000) )\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby( 'competition_distance_binned' ).sum().reset_index()\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H3.** Lojas com competidores à mais tempo deveriam vendem mais.\n",
    "**FALSE** Lojas com COMPETIDORES À MAIS TEMPO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.507566Z",
     "start_time": "2022-08-14T00:10:06.507566Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plt.subplot( 1, 3, 1 )\n",
    "aux1 = df4[['competition_time_month', 'sales']].groupby( 'competition_time_month' ).sum().reset_index()\n",
    "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & ( aux1['competition_time_month'] != 0 )]\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson'), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "**FALSA** Lojas com promocoes ativas por mais tempo vendem menos, depois de um certo periodo de promocao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.510565Z",
     "start_time": "2022-08-14T00:10:06.510565Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
    "\n",
    "grid = GridSpec( 2, 3 )\n",
    "\n",
    "plt.subplot( grid[0,0] )\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[0,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( grid[1,0] )\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[1,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "\n",
    "plt.subplot( grid[:,2] )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### <s>**H5.** Lojas com mais dias de promoção deveriam vender mais.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H7.** Lojas com mais promoções consecutivas deveriam vender mais.\n",
    "**FALSA** Lojas com mais promocoes consecutivas vendem menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.512563Z",
     "start_time": "2022-08-14T00:10:06.512563Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2'] ).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.515564Z",
     "start_time": "2022-08-14T00:10:06.515564Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "\n",
    "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "\n",
    "ax.legend( labels=['Tradicional & Extendida', 'Extendida']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "### **H8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "**FALSA** Lojas abertas durante o feriado do Natal vendem menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.518618Z",
     "start_time": "2022-08-14T00:10:06.518618Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot( 1, 2, 1 )\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby( 'state_holiday' ).sum().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 2, 2 )\n",
    "aux2 = aux[['year', 'state_holiday', 'sales']].groupby( ['year', 'state_holiday'] ).sum().reset_index()\n",
    "sns.barplot( x='year', y='sales', hue='state_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "### **H9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "**FALSA** Lojas vendem menos ao longo dos anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.523745Z",
     "start_time": "2022-08-14T00:10:06.523745Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year', 'sales']].groupby( 'year' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "### **H10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "**FALSA** Lojas vendem menos no segundo semestre do ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.525745Z",
     "start_time": "2022-08-14T00:10:06.525745Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby( 'month' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "### **H11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "**VERDADEIRA** Lojas vendem mais depois do dia 10 de cada mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.528743Z",
     "start_time": "2022-08-14T00:10:06.528743Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day', 'sales']].groupby( 'day' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 1 )\n",
    "sns.barplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.regplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
    "aux2 =aux1[['before_after', 'sales']].groupby( 'before_after' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.barplot( x='before_after', y='sales', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "### **H12.** Lojas deveriam vender menos aos finais de semana.\n",
    "**VERDADEIRA** Lojas vendem menos nos final de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.531741Z",
     "start_time": "2022-08-14T00:10:06.531741Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    }
   },
   "source": [
    "### **H13.** Lojas deveriam vender menos durante os feriados escolares.\n",
    "**VERDADEIRA** Lojas vendem menos durante os feriadso escolares, except os meses de Julho e Agosto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.533739Z",
     "start_time": "2022-08-14T00:10:06.533739Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby( 'school_holiday' ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 1 )\n",
    "sns.barplot( x='school_holiday', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby( ['month','school_holiday'] ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 2 )\n",
    "sns.barplot( x='month', y='sales', hue='school_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Resumo das Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.537747Z",
     "start_time": "2022-08-14T00:10:06.537747Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.540745Z",
     "start_time": "2022-08-14T00:10:06.539745Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tab =[['Hipoteses', 'Conclusao', 'Relevancia'],\n",
    "      ['H1', 'Falsa', 'Baixa'],  \n",
    "      ['H2', 'Falsa', 'Media'],  \n",
    "      ['H3', 'Falsa', 'Media'],\n",
    "      ['H4', 'Falsa', 'Baixa'],\n",
    "      ['H5', '-', '-'],\n",
    "      ['H7', 'Falsa', 'Baixa'],\n",
    "      ['H8', 'Falsa', 'Media'],\n",
    "      ['H9', 'Falsa', 'Alta'],\n",
    "      ['H10', 'Falsa', 'Alta'],\n",
    "      ['H11', 'Verdadeira', 'Alta'],\n",
    "      ['H12', 'Verdadeira', 'Alta'],\n",
    "      ['H13', 'Verdadeira', 'Baixa'],\n",
    "     ]  \n",
    "print( tabulate( tab, headers='firstrow' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Analise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.543746Z",
     "start_time": "2022-08-14T00:10:06.543746Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "correlation = num_attributes.corr( method='pearson' )\n",
    "sns.heatmap( correlation, annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.545744Z",
     "start_time": "2022-08-14T00:10:06.545744Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# only categorical data\n",
    "a = df4.select_dtypes( include='object' )\n",
    "\n",
    "# Calculate cramer V\n",
    "a1 = cramer_v( a['state_holiday'], a['state_holiday'] )\n",
    "a2 = cramer_v( a['state_holiday'], a['store_type'] )\n",
    "a3 = cramer_v( a['state_holiday'], a['assortment'] )\n",
    "\n",
    "a4 = cramer_v( a['store_type'], a['state_holiday'] )\n",
    "a5 = cramer_v( a['store_type'], a['store_type'] )\n",
    "a6 = cramer_v( a['store_type'], a['assortment'] )\n",
    "\n",
    "a7 = cramer_v( a['assortment'], a['state_holiday'] )\n",
    "a8 = cramer_v( a['assortment'], a['store_type'] )\n",
    "a9 = cramer_v( a['assortment'], a['assortment'] )\n",
    "\n",
    "# Final dataset\n",
    "d = pd.DataFrame( {'state_holiday': [a1, a2, a3], \n",
    "               'store_type': [a4, a5, a6],\n",
    "               'assortment': [a7, a8, a9]  })\n",
    "d = d.set_index( d.columns )\n",
    "\n",
    "sns.heatmap( d, annot=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. PASSO 05 - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.548741Z",
     "start_time": "2022-08-14T00:10:06.548741Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Normalizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.551781Z",
     "start_time": "2022-08-14T00:10:06.551781Z"
    }
   },
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "# competition distance\n",
    "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
    "pickle.dump( rs, open( 'parameter/competition_distance_scaler.pkl', 'wb') )\n",
    "\n",
    "# competition time month\n",
    "df5['competition_time_month'] = rs.fit_transform( df5[['competition_time_month']].values )\n",
    "pickle.dump( rs, open( 'parameter/competition_time_month_scaler.pkl', 'wb') )\n",
    "\n",
    "# promo time week\n",
    "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
    "pickle.dump( rs, open( 'parameter/promo_time_week_scaler.pkl', 'wb') )\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform( df5[['year']].values )\n",
    "pickle.dump( mms, open( 'parameter/year_scaler.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Transformacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.555968Z",
     "start_time": "2022-08-14T00:10:06.555968Z"
    }
   },
   "outputs": [],
   "source": [
    "# state_holiday - One Hot Encoding\n",
    "df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
    "pickle.dump( le, open( 'parameter/store_type_scaler.pkl', 'wb') )\n",
    "\n",
    "# assortment - Ordinal Encoding\n",
    "assortment_dict = {'basic': 1,  'extra': 2, 'extended': 3}\n",
    "df5['assortment'] = df5['assortment'].map( assortment_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Response Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.558966Z",
     "start_time": "2022-08-14T00:10:06.558966Z"
    }
   },
   "outputs": [],
   "source": [
    "df5['sales'] = np.log1p( df5['sales'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3. Nature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.561965Z",
     "start_time": "2022-08-14T00:10:06.561965Z"
    }
   },
   "outputs": [],
   "source": [
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "# month\n",
    "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "# day \n",
    "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. PASSO 06 - FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.564965Z",
     "start_time": "2022-08-14T00:10:06.564965Z"
    }
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Split dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.568266Z",
     "start_time": "2022-08-14T00:10:06.568266Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_drop = ['week_of_year', 'day', 'month', 'day_of_week', 'promo_since', 'competition_since', 'year_week' ]\n",
    "df6 = df6.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.571373Z",
     "start_time": "2022-08-14T00:10:06.571373Z"
    }
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "# test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print( 'Training Min Date: {}'.format( X_train['date'].min() ) )\n",
    "print( 'Training Max Date: {}'.format( X_train['date'].max() ) )\n",
    "\n",
    "print( '\\nTest Min Date: {}'.format( X_test['date'].min() ) )\n",
    "print( 'Test Max Date: {}'.format( X_test['date'].max() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.574371Z",
     "start_time": "2022-08-14T00:10:06.574371Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## training and test dataset for Boruta\n",
    "#X_train_n = X_train.drop( ['date', 'sales'], axis=1 ).values\n",
    "#y_train_n = y_train.values.ravel()\n",
    "#\n",
    "## define RandomForestRegressor\n",
    "#rf = RandomForestRegressor( n_jobs=-1 )\n",
    "#\n",
    "## define Boruta\n",
    "#boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit( X_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1. Best Features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.576372Z",
     "start_time": "2022-08-14T00:10:06.576372Z"
    }
   },
   "outputs": [],
   "source": [
    "#cols_selected = boruta.support_.tolist()\n",
    "#\n",
    "## best features\n",
    "#X_train_fs = X_train.drop( ['date', 'sales'], axis=1 )\n",
    "#cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "#\n",
    "## not selected boruta\n",
    "#cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns, cols_selected_boruta ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:06.863752Z",
     "start_time": "2022-08-14T00:10:06.844766Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_selected_boruta = [\n",
    "    'store',\n",
    "    'promo',\n",
    "    'store_type',\n",
    "    'assortment',\n",
    "    'competition_distance',\n",
    "    'competition_open_since_month',\n",
    "    'competition_open_since_year',\n",
    "    'promo2',\n",
    "    'promo2_since_week',\n",
    "    'promo2_since_year',\n",
    "    'competition_time_month',\n",
    "    'promo_time_week',\n",
    "    'day_of_week_sin',\n",
    "    'day_of_week_cos',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'day_sin',\n",
    "    'day_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos']\n",
    "\n",
    "# columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0. PASSO 07 - MACHINE LEARNING MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:07.286135Z",
     "start_time": "2022-08-14T00:10:07.263226Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m[ cols_selected_boruta ]\n\u001b[0;32m      2\u001b[0m x_test \u001b[38;5;241m=\u001b[39m X_test[ cols_selected_boruta ]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Time Series Data Preparation\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = X_train[ cols_selected_boruta ]\n",
    "x_test = X_test[ cols_selected_boruta ]\n",
    "\n",
    "# Time Series Data Preparation\n",
    "x_training = X_train[ cols_selected_boruta_full ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:07.759252Z",
     "start_time": "2022-08-14T00:10:07.720275Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m aux1 \u001b[38;5;241m=\u001b[39m \u001b[43mx_test\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m aux1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# prediction\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "\n",
    "# prediction\n",
    "aux2 = aux1[['store', 'sales']].groupby( 'store' ).mean().reset_index().rename( columns={'sales': 'predictions'} )\n",
    "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
    "yhat_baseline = aux1['predictions']\n",
    "\n",
    "# performance\n",
    "baseline_result = ml_error( 'Average Model', np.expm1( y_test ), np.expm1( yhat_baseline ) )\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:08.185637Z",
     "start_time": "2022-08-14T00:10:08.147660Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m()\u001b[38;5;241m.\u001b[39mfit( x_train, y_train )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m yhat_lr \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict( x_test )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lr = LinearRegression().fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lr = lr.predict( x_test )\n",
    "\n",
    "# performance\n",
    "lr_result = ml_error( 'Linear Regression', np.expm1( y_test ), np.expm1( yhat_lr ) )\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. Linear Regression Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:08.626864Z",
     "start_time": "2022-08-14T00:10:08.591886Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr_result_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m( x_training, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m'\u001b[39m, lr, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[0;32m      2\u001b[0m lr_result_cv\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "lr_result_cv = cross_validation( x_training, 5, 'Linear Regression', lr, verbose=False )\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Linear Regression Regularized Model - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:09.068964Z",
     "start_time": "2022-08-14T00:10:09.030987Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lrr \u001b[38;5;241m=\u001b[39m \u001b[43mLasso\u001b[49m( alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m )\u001b[38;5;241m.\u001b[39mfit( x_train, y_train )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m yhat_lrr \u001b[38;5;241m=\u001b[39m lrr\u001b[38;5;241m.\u001b[39mpredict( x_test )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lrr = Lasso( alpha=0.01 ).fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lrr = lrr.predict( x_test )\n",
    "\n",
    "# performance\n",
    "lrr_result = ml_error( 'Linear Regression - Lasso', np.expm1( y_test ), np.expm1( yhat_lrr ) )\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1.  Lasso - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:09.522163Z",
     "start_time": "2022-08-14T00:10:09.489898Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lrr_result_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m( x_training, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLasso\u001b[39m\u001b[38;5;124m'\u001b[39m, lrr, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[0;32m      2\u001b[0m lrr_result_cv\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "lrr_result_cv = cross_validation( x_training, 5, 'Lasso', lrr, verbose=False )\n",
    "lrr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:09.930743Z",
     "start_time": "2022-08-14T00:10:09.892602Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestRegressor\u001b[49m( n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m )\u001b[38;5;241m.\u001b[39mfit( x_train, y_train )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m yhat_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict( x_test )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# model\n",
    "rf = RandomForestRegressor( n_estimators=100, n_jobs=-1, random_state=42 ).fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_rf = rf.predict( x_test )\n",
    "\n",
    "# performance\n",
    "rf_result = ml_error( 'Random Forest Regressor', np.expm1( y_test ), np.expm1( yhat_rf ) )\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1.  Random Forest Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:10.336706Z",
     "start_time": "2022-08-14T00:10:10.312532Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rf_result_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m( x_training, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest Regressor\u001b[39m\u001b[38;5;124m'\u001b[39m, rf, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[0;32m      2\u001b[0m rf_result_cv\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "rf_result_cv = cross_validation( x_training, 5, 'Random Forest Regressor', rf, verbose=True )\n",
    "rf_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:10.788529Z",
     "start_time": "2022-08-14T00:10:10.755545Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241m.\u001b[39mXGBRegressor( objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                               n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m      4\u001b[0m                               eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, \n\u001b[0;32m      5\u001b[0m                               max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m      6\u001b[0m                               subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m      7\u001b[0m                               colsample_bytee\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m )\u001b[38;5;241m.\u001b[39mfit( x_train, y_train )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# prediction\u001b[39;00m\n\u001b[0;32m     10\u001b[0m yhat_xgb \u001b[38;5;241m=\u001b[39m model_xgb\u001b[38;5;241m.\u001b[39mpredict( x_test )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                              n_estimators=100, \n",
    "                              eta=0.01, \n",
    "                              max_depth=10, \n",
    "                              subsample=0.7,\n",
    "                              colsample_bytee=0.9 ).fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_xgb = model_xgb.predict( x_test )\n",
    "\n",
    "# performance\n",
    "xgb_result = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1( yhat_xgb ) )\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1. XGBoost Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:11.231314Z",
     "start_time": "2022-08-14T00:10:11.201980Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xgb_result_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m( x_training, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost Regressor\u001b[39m\u001b[38;5;124m'\u001b[39m, model_xgb, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[0;32m      2\u001b[0m xgb_result_cv\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_result_cv = cross_validation( x_training, 5, 'XGBoost Regressor', model_xgb, verbose=True )\n",
    "xgb_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. Compare Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:11.871279Z",
     "start_time": "2022-08-14T00:10:11.835301Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m modelling_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat( [\u001b[43mbaseline_result\u001b[49m, lr_result, lrr_result, rf_result, xgb_result] )\n\u001b[0;32m      2\u001b[0m modelling_result\u001b[38;5;241m.\u001b[39msort_values( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'baseline_result' is not defined"
     ]
    }
   ],
   "source": [
    "modelling_result = pd.concat( [baseline_result, lr_result, lrr_result, rf_result, xgb_result] )\n",
    "modelling_result.sort_values( 'RMSE' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. Real Performance - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-14T00:10:12.287977Z",
     "start_time": "2022-08-14T00:10:12.246921Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_result_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m modelling_result_cv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat( [\u001b[43mlr_result_cv\u001b[49m, lrr_result_cv, rf_result_cv, xgb_result_cv] )\n\u001b[0;32m      2\u001b[0m modelling_result_cv\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_result_cv' is not defined"
     ]
    }
   ],
   "source": [
    "modelling_result_cv = pd.concat( [lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv] )\n",
    "modelling_result_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
